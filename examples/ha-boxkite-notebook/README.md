# Boxkite Demo

## Notebook
```bash
jupyter notebook
```

If Jupyter is not installed:
```bash
pip install jupyterlab
```

## Data format

Boxkite is basically useful for a regression or classification model whose prediction problem can be generalized as <code>[feature-1, feature-2, ..., feature-n] => inference</code>.

### Training (offline)

For the training (a.k.a. baseline) features and inference, it is logged by the function <code>export_text()</code>.
```python
from boxkite.monitoring.service import ModelMonitoringService

ModelMonitoringService.export_text(
    features=features, inference=inference, path='hist.txt',
)
```

The data format of features and inference are as below:
```python
features = [("age", [33, 23, 54]), ("sex", [1, 0, 1])]
inference = ["cat1", "cat2", "cat1"]
```

Both the features and inference can be of continuous or discrete values. For discrete values, they needs to be encoded to number in advance, otherwise the error <code>ValueError: could not convert string to float: 'male'</code> will occur.

The [lines](https://github.com/tintinrevient/boxkite/blob/a8d1063d5f49af3261d41466e545a8fbd1e17a0b/boxkite/monitoring/collector/feature.py#L123-L126) to iterate through the feature name <code>name</code> and its list of values <code>val</code> to be converted to <code>float</code> is as below:
```python
name, val = col
# Assuming data is float. Categorical data should have been one-hot encoded
# dtype=float will convert None values to np.nan as well
val = np.asarray(val, dtype=float)
```

### Scoring (online)

For the scoring features and inference, it is logged by the function <code>log_prediction()</code>. <code>request_body=request.data</code> is not used further down the execution chain, thus it can be **replaced with** <code>request_body=None</code>.
```python
from boxkite.monitoring.collector import BaselineMetricCollector
from boxkite.monitoring.service import ModelMonitoringService

monitor = ModelMonitoringService(
    baseline_collector=BaselineMetricCollector(path='hist.txt')
)

monitor.log_prediction(
    request_body=request.data,
    features=features,
    output=score,
)
```

The data format of features and inference are as below:
```python
features = [33, 1]
score = "cat1"
```

It is worth noting that only a single inference can be logged.

These [lines](https://github.com/tintinrevient/boxkite/blob/638414cce2a3265be1872ebf1eab434785a3a22c/boxkite/monitoring/registry.py#L65-L67) validate whether the inference is a single value:
```python
# Do nothing if output is individual class probability
if self._inference_metric and is_single_value(prediction.output):
    self._inference_metric.observe(prediction.output)
```

These [lines](https://github.com/tintinrevient/boxkite/blob/638414cce2a3265be1872ebf1eab434785a3a22c/boxkite/monitoring/registry.py#L71-L74) validate whether each feature is a single value:
```python
for i, v in enumerate(prediction.features):
    # Unflattened tensors are unsupported, ignore
     if i in self._feature_metrics and is_single_value(v):
        self._feature_metrics[i].observe(v)
```

### Feature indexing

To log the training and scoring data, the order of features MUST be **matched** because of feature indexing. The indexed feature names are generated by <code>enumerate()</code> which are "feature_1_value", "feature_2_value", etc. Each indexed feature name is bundled with its own calculated bins respectively.

These [lines](https://github.com/tintinrevient/boxkite/blob/a8d1063d5f49af3261d41466e545a8fbd1e17a0b/boxkite/monitoring/collector/feature.py#L138-L146) index and record the training features offline.
```bash
if "+Inf" not in bin_to_count:
    metric = FeatureDistribution.as_discrete(
        index=i, name=name, bin_to_count=bin_to_count
    )
else:
    val = _remove_nans_and_infs(val)
    metric = FeatureDistribution.as_continuous(
        index=i, name=name, bin_to_count=bin_to_count, sum_value=np.sum(val)
    )
```

These [lines](https://github.com/tintinrevient/boxkite/blob/a8d1063d5f49af3261d41466e545a8fbd1e17a0b/boxkite/monitoring/registry.py#L71-L74) index and store the scoring features online.
```python
for i, v in enumerate(prediction.features):
    # Unflattened tensors are unsupported, ignore
    if i in self._feature_metrics and is_single_value(v):
        self._feature_metrics[i].observe(v)
```

In [frequency.py](https://github.com/tintinrevient/boxkite/blob/a8d1063d5f49af3261d41466e545a8fbd1e17a0b/boxkite/monitoring/frequency.py), the function <code>dump_frequency()</code> logs the training histogram, and the function <code>observe()</code> records the scoring histogram.

### Aggregate histogram

To aggregate the offline and online histograms, the function <code>export_http()</code> is used, which retrieves the data from <code>_baseline_collector</code> (offline), <code>_live_metrics</code> (online) and <code>_info_collector</code> (metadata). The source code is [here](https://github.com/tintinrevient/boxkite/blob/master/boxkite/monitoring/service.py#L33-L46).
```python
from boxkite.monitoring.collector import BaselineMetricCollector
from boxkite.monitoring.service import ModelMonitoringService

monitor = ModelMonitoringService(
    baseline_collector=BaselineMetricCollector(path='hist.txt')
)

result = monitor.export_http()[0]
```

It is worth noting that the live data, e.g., <code>_live_metrics</code>, exists only **in memory**. When prometheus pulls the live data via REST API, it can be then stored persistently in prometheus <code>data</code> directory. The test is [here](./test).

The result of all the data is as below:
```html
# HELP feature_0_value_baseline Baseline values for feature: age
# TYPE feature_0_value_baseline histogram
feature_0_value_baseline_bucket{le="23.0"} 1.0
feature_0_value_baseline_bucket{le="33.333333333333336"} 2.0
feature_0_value_baseline_bucket{le="43.66666666666667"} 2.0
feature_0_value_baseline_bucket{le="54.0"} 3.0
feature_0_value_baseline_bucket{le="+Inf"} 3.0
feature_0_value_baseline_count 3.0
feature_0_value_baseline_sum 110.0
# HELP feature_1_value_baseline_total Baseline values for feature: sex
# TYPE feature_1_value_baseline_total counter
feature_1_value_baseline_total{bin="0.0"} 1.0
feature_1_value_baseline_total{bin="1.0"} 2.0
# HELP inference_value_baseline_total Baseline inference values for test set
# TYPE inference_value_baseline_total counter
inference_value_baseline_total{bin="cat1"} 2.0
inference_value_baseline_total{bin="cat2"} 1.0
# HELP inference_value_total Real time inference values for test set
# TYPE inference_value_total counter
inference_value_total{bin="cat1"} 1.0
inference_value_total{bin="cat2"} 0.0
# HELP inference_value_created Real time inference values for test set
# TYPE inference_value_created gauge
inference_value_created{bin="cat1"} 1.6401179371241732e+09
inference_value_created{bin="cat2"} 1.640117937124185e+09
# HELP feature_0_value Real time values for feature: age
# TYPE feature_0_value histogram
feature_0_value_bucket{le="23.0"} 0.0
feature_0_value_bucket{le="33.333333333333336"} 1.0
feature_0_value_bucket{le="43.66666666666667"} 1.0
feature_0_value_bucket{le="54.0"} 1.0
feature_0_value_bucket{le="+Inf"} 1.0
feature_0_value_count 1.0
feature_0_value_sum 33.0
# HELP feature_0_value_created Real time values for feature: age
# TYPE feature_0_value_created gauge
feature_0_value_created 1.6401179371239989e+09
# HELP feature_1_value_total Real time values for feature: sex
# TYPE feature_1_value_total counter
feature_1_value_total{bin="0.0"} 0.0
feature_1_value_total{bin="1.0"} 1.0
# HELP feature_1_value_created Real time values for feature: sex
# TYPE feature_1_value_created gauge
feature_1_value_created{bin="0.0"} 1.6401179371240928e+09
feature_1_value_created{bin="1.0"} 1.640117937124115e+09
# HELP baseline_metrics_info Metadata about the baseline training metrics
# TYPE baseline_metrics_info gauge
baseline_metrics_info{feature_name="age",metric_name="feature_0_value_baseline",metric_type="histogram"} 1.0
baseline_metrics_info{feature_name="sex",metric_name="feature_1_value_baseline",metric_type="counter"} 1.0
baseline_metrics_info{feature_name="Baseline inference values for test set",metric_name="inference_value_baseline",metric_type="counter"} 1.0
```

## References
* https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
* https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/
* https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/
* https://docs.docker.com/engine/reference/commandline/run/